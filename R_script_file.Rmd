---
title: "module_8_Assignment_43513429"
author: "Phanindra Neeli"
date: "2023-10-23"
output: word_document
---

```{r}
#1.	Load the file “Module 8 Assignment Data.xlsx” into R.  This file contains information on 500 women age 55 and above and any recent bone fractures they have experienced.  The data comes from the Global Longitudinal study of Osteoporosis in Women (GLOW) project.  This is your master data set.

rm(list=ls())
glow=rio::import("6304 Module 8 Assignment Data.xlsx")
```

```{r}
#2.	Using the numerical portion of your U number as a random number seed, take a random sample of 150 cases from the full data set using the method presented in class. This will be your primary data set.

set.seed(43513429)
glow_sample = glow[sample(nrow(glow),150),]
colnames(glow_sample)=tolower(make.names(colnames(glow_sample)))
attach(glow_sample)

```

```{r}
#1.	Show the results of the str() command on your primary data set.

str(glow_sample)
```
```{r}
#2.	Parameterize a full logistic regression model with FRACTURE as the dependent and all other variables as independent (excluding the CASE variable).

glow_out = glm(fracture~priorfrac+momfrac+age+bmi+height+weight+menoby45+armassist,data = glow_sample,family = binomial)
glow_out
```
```{r}
#3.	Using the summary() command report the results of the model from Part 2.

summary(glow_out)
```

```{r}
#4.	State whether you believe the Residual Deviance of your model is markedly different from the Null Deviance.

#From the above full logistic regression summary we can see the null deviance(only intercept) is 165.32 where as residual deviance(includes independent varibles) is  144.89 .so the  Residual Deviance of the logistic regression model is notably lower than the Null Deviance, indicating that the model provides a better fit to the data compared to a null model with no predictors. This suggests that the predictors in the model are contributing significantly to explaining the variation in the response variable.
```

```{r}
#5.	Given your model from Part 2 and ignoring p values, which variable will have the greatest influence in increasing the modeled probability that a subject will have recently experienced a bone fracture?

# I think the priorFrac vairable would be greatest influencer in increasing the modeled probablility since the priorfrac has the highest positive coefficient estimate (1.244102), indicating that an increase in the "priorfrac" value results in the most significant increase in the log-odds of experiencing a bone fracture.  
```

```{r}
#6.	Given your model from Part 2 and ignoring p values, which variable will have the greatest influence in decreasing the modeled probability that a subject will have recently experienced a bone fracture?

# The "momfrac" variable has the most negative coefficient estimate (-0.236433), making it the variable that has the greatest influence in decreasing the modeled probability of a subject having recently experienced a bone fracture.
```

```{r}
#7.	Use the expand.grid() function develop a prediction object with all independent variables in the Part 2 model. For binary independent variables use the unique() function.  For numerical (continuous) independent variables use the quantile() function and set test levels at the 0th, 25th, 50th, 75th, and 100th percentiles for the variables as appearing in your reduced data set.  Use these values to calculate independent variable values and predicted probabilities for all the cases generated by your expand.grid() statement.   Show the results of the str() command when applied to your prediction object.

pred.data=expand.grid(priorfrac=unique(priorfrac),
                      menoby45=unique(menoby45),momfrac=unique(momfrac),
                      armassist=unique(armassist),
                      age=quantile(age,c(0,.25,.5,.75,1)),weight=quantile(weight,c(0,.25,.5,.75,1)),height=quantile(height,c(0,.25,.5,.75,1)),bmi=quantile(bmi,c(0,.25,.5,.75,1)))
pred.probs=round(predict(glow_out,
                         newdata=pred.data,type="response"),6)
glow.predictions=cbind(pred.data,pred.probs)
str(glow.predictions)
```

```{r}
#8.	Based on your predictions generated in Part 7, report the maximum and minimum predicted probabilities generated.


#Maximum Prob
glow.predictions[which.max
                   (glow.predictions$pred.probs),]


#Minimum Prob
glow.predictions[which.min
                   (glow.predictions$pred.probs),]

```

